{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "import guidance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('measure-results-qa.json') as f:\n",
    "    qa_results = json.load(f)\n",
    "\n",
    "with open('measure-results.json') as f:\n",
    "    finetune_results = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qa_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick best model (see other notebook)\n",
    "mid = 'ft-7xUj5LuaGNe45xXZcMRgVlF2'\n",
    "finetune_results = [d for d in finetune_results if d['model']['id'] == mid][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = '''Is 2022 feeling more like a \"normal\" year for you?'''\n",
    "reference = '''Thankfully 2022 has felt a bit more like a “normal” year.  I saw slightly more people in person, got into a groove at work, and continued to play and have fun with my daughter.  It’s not quite like it was before the pandemic but it doesn’t feel strange anymore.  It’s not clear whether it’s because I’m getting used to this new environment, or if it is actually getting back to normal.  Like most things, it’s probably a mix of both.'''\n",
    "hypothesis = '''Yes, 2022 is feeling more like a \"normal\" year for me. I'm seeing slightly more people in person, getting into a groove at work, and continuing to play and have fun with my daughter. It's not quite like it was before the pandemic, but it doesn't feel strange anymore. I\\'m getting used to this new environment and it's nice to get into a groove where I can start to feel productive in many different areas of my life.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'0': 0.0,\n",
       "  '1': 0.0,\n",
       "  '2': 0.0,\n",
       "  '3': 0.0,\n",
       "  '4': 0.0,\n",
       "  '5': 0.0,\n",
       "  '6': 0.0035792483573586094,\n",
       "  '7': 0.3304311187610009,\n",
       "  '8': 0.10131157024200545,\n",
       "  '9': 0.2934031560077535,\n",
       "  '10': 0.2712749066318814},\n",
       " '8')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_gpt35 = \"\"\"QUESTION: {{question}}\n",
    "\n",
    "ANSWER: {{reference}}\n",
    "\n",
    "PROPOSED ANSWER: {{hypothesis}}\n",
    "\n",
    "Can you rate the PROPOSED ANSWER to the above QUESTION from 0 (not even close) to 10 (exact meaning) on whether or not it matches ANSWER?  Only output the number.\n",
    "{{select 'rating' options=valid_nums logprobs='logprobs'}}\"\"\"\n",
    "\n",
    "prompt_gpt4 = \"\"\"{{#system~}}\n",
    "You are a helpful assistant.\n",
    "{{~/system}}\n",
    "{{#user~}}\n",
    "QUESTION: {{question}}\n",
    "\n",
    "ANSWER: {{reference}}\n",
    "\n",
    "PROPOSED ANSWER: {{hypothesis}}\n",
    "\n",
    "Can you rate the PROPOSED ANSWER to the above QUESTION from 0 (not even close) to 10 (exact meaning) on whether or not it matches ANSWER?  Only output the number.\n",
    "{{~/user}}\n",
    "{{#assistant~}}\n",
    "{{gen 'rating' temperature=0 max_tokens=2}}\n",
    "{{~/assistant}}\"\"\"\n",
    "\n",
    "def rate(model, question, reference, hypothesis):\n",
    "    assert model in ['gpt-4', \"text-davinci-003\"]\n",
    "    \n",
    "    guidance.llm = guidance.llms.OpenAI(model)\n",
    "    valid_nums = [f'{i}' for i in range(0, 11)]\n",
    "   \n",
    "    \n",
    "    program = guidance(prompt_gpt4 if model == 'gpt-4' else prompt_gpt35, silent=True)\n",
    "    \n",
    "    # execute the program on a specific proverb\n",
    "    executed_program = program(\n",
    "        question=question,\n",
    "        reference=reference,\n",
    "        hypothesis=hypothesis,\n",
    "        valid_nums=valid_nums,\n",
    "    )\n",
    "    return executed_program['rating'] if model == 'gpt-4' else dict(zip(executed_program['logprobs'].keys(), softmax(list(executed_program['logprobs'].values()))))\n",
    "\n",
    "output35 = rate('text-davinci-003', question, reference, hypothesis)\n",
    "output4 = rate('gpt-4', question, reference, hypothesis)\n",
    "output35, output4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Processed 10 of 669\n",
      "* Processed 20 of 669\n",
      "* Processed 30 of 669\n",
      "* Processed 40 of 669\n",
      "* Processed 50 of 669\n",
      "* Processed 60 of 669\n",
      "* Processed 70 of 669\n",
      "* Processed 80 of 669\n",
      "* Processed 90 of 669\n",
      "* Processed 100 of 669\n",
      "* Processed 110 of 669\n",
      "* Processed 120 of 669\n",
      "* Processed 130 of 669\n",
      "* Processed 140 of 669\n",
      "* Processed 150 of 669\n",
      "* Processed 160 of 669\n",
      "* Processed 170 of 669\n",
      "* Processed 180 of 669\n",
      "* Processed 190 of 669\n",
      "* Processed 200 of 669\n",
      "* Processed 210 of 669\n",
      "* Processed 220 of 669\n",
      "* Processed 230 of 669\n",
      "* Processed 240 of 669\n",
      "* Processed 250 of 669\n",
      "* Processed 260 of 669\n",
      "* Processed 270 of 669\n",
      "* Processed 280 of 669\n",
      "* Processed 290 of 669\n",
      "* Processed 300 of 669\n",
      "* Processed 310 of 669\n",
      "* Processed 320 of 669\n",
      "* Processed 330 of 669\n",
      "* Processed 340 of 669\n",
      "* Processed 350 of 669\n",
      "* Processed 360 of 669\n",
      "* Processed 370 of 669\n",
      "* Processed 380 of 669\n",
      "* Processed 390 of 669\n",
      "* Processed 400 of 669\n",
      "* Processed 410 of 669\n",
      "* Processed 420 of 669\n",
      "* Processed 430 of 669\n",
      "* Processed 440 of 669\n",
      "* Processed 450 of 669\n",
      "* Processed 460 of 669\n",
      "* Processed 470 of 669\n",
      "* Processed 480 of 669\n",
      "* Processed 490 of 669\n",
      "* Processed 500 of 669\n",
      "* Processed 510 of 669\n",
      "* Processed 520 of 669\n",
      "* Processed 530 of 669\n",
      "* Processed 540 of 669\n",
      "* Processed 550 of 669\n",
      "* Processed 560 of 669\n",
      "* Processed 570 of 669\n",
      "* Processed 580 of 669\n",
      "* Processed 590 of 669\n",
      "* Processed 600 of 669\n",
      "* Processed 610 of 669\n",
      "* Processed 620 of 669\n",
      "* Processed 630 of 669\n",
      "* Processed 640 of 669\n",
      "* Processed 650 of 669\n",
      "* Processed 660 of 669\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i, entry in enumerate(qa_results['data']):\n",
    "    question = entry['training_data']['prompt']\n",
    "    reference = entry['reference']\n",
    "    hypothesis = entry['hypothesis']\n",
    "    \n",
    "    result = entry.copy()\n",
    "    result['gpt35'] = rate('text-davinci-003', question, reference, hypothesis)\n",
    "    result['gpt4'] = rate('gpt-4', question, reference, hypothesis)\n",
    "    \n",
    "    results.append(result)\n",
    "    \n",
    "    if (i + 1) % 10 == 0:\n",
    "        time.sleep(5)\n",
    "        print(f\"* Processed {i+1} of {len(qa_results['data'])}\")\n",
    "\n",
    "results\n",
    "\n",
    "with open('measure-results-qa-gpt.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Processed 10 of 669\n",
      "* Processed 20 of 669\n",
      "* Processed 30 of 669\n",
      "* Processed 40 of 669\n",
      "* Processed 50 of 669\n",
      "* Processed 60 of 669\n",
      "* Processed 70 of 669\n",
      "* Processed 80 of 669\n",
      "* Processed 90 of 669\n",
      "* Processed 100 of 669\n",
      "* Processed 110 of 669\n",
      "* Processed 120 of 669\n",
      "* Processed 130 of 669\n",
      "* Processed 140 of 669\n",
      "* Processed 150 of 669\n",
      "* Processed 160 of 669\n",
      "* Processed 170 of 669\n",
      "* Processed 180 of 669\n",
      "* Processed 190 of 669\n",
      "* Processed 200 of 669\n",
      "* Processed 210 of 669\n",
      "* Processed 220 of 669\n",
      "* Processed 230 of 669\n",
      "* Processed 240 of 669\n",
      "* Processed 250 of 669\n",
      "* Processed 260 of 669\n",
      "* Processed 270 of 669\n",
      "* Processed 280 of 669\n",
      "* Processed 290 of 669\n",
      "* Processed 300 of 669\n",
      "* Processed 310 of 669\n",
      "* Processed 320 of 669\n",
      "* Processed 330 of 669\n",
      "* Processed 340 of 669\n",
      "* Processed 350 of 669\n",
      "* Processed 360 of 669\n",
      "* Processed 370 of 669\n",
      "* Processed 380 of 669\n",
      "* Processed 390 of 669\n",
      "* Processed 400 of 669\n",
      "* Processed 410 of 669\n",
      "* Processed 420 of 669\n",
      "* Processed 430 of 669\n",
      "* Processed 440 of 669\n",
      "* Processed 450 of 669\n",
      "* Processed 460 of 669\n",
      "* Processed 470 of 669\n",
      "* Processed 480 of 669\n",
      "* Processed 490 of 669\n",
      "* Processed 500 of 669\n",
      "* Processed 510 of 669\n",
      "* Processed 520 of 669\n",
      "* Processed 530 of 669\n",
      "* Processed 540 of 669\n",
      "* Processed 550 of 669\n",
      "* Processed 560 of 669\n",
      "* Processed 570 of 669\n",
      "* Processed 580 of 669\n",
      "* Processed 590 of 669\n",
      "* Processed 600 of 669\n",
      "* Processed 610 of 669\n",
      "* Processed 620 of 669\n",
      "* Processed 630 of 669\n",
      "* Processed 640 of 669\n",
      "* Processed 650 of 669\n",
      "* Processed 660 of 669\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i, entry in enumerate(finetune_results['data']):\n",
    "    question = entry['training_data']['prompt']\n",
    "    reference = entry['reference']\n",
    "    hypothesis = entry['hypothesis']\n",
    "    \n",
    "    result = entry.copy()\n",
    "    result['gpt35'] = rate('text-davinci-003', question, reference, hypothesis)\n",
    "    result['gpt4'] = rate('gpt-4', question, reference, hypothesis)\n",
    "    \n",
    "    results.append(result)\n",
    "    \n",
    "    if (i + 1) % 10 == 0:\n",
    "        time.sleep(5)\n",
    "        print(f\"* Processed {i+1} of {len(finetune_results['data'])}\")\n",
    "\n",
    "results\n",
    "\n",
    "with open('measure-results-finetune-gpt.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
