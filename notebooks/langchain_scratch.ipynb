{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQAWithSourcesChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 900\n",
    "chunk_overlap = 0\n",
    "embedding_model = 'text-embedding-ada-002'\n",
    "llm_model = 'text-davinci-003'\n",
    "max_tokens = 256\n",
    "temperature = 0.7\n",
    "\n",
    "prompt = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Helpful answer in less than 50 words:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source': '../test.txt', 'url': 'https://xyz'}]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = TextLoader('../test.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "for d in documents:\n",
    "    d.metadata['url'] = 'https://xyz'\n",
    "\n",
    "[doc.metadata for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 2885, which is longer than the specified 900\n",
      "Created a chunk of size 5284, which is longer than the specified 900\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=chunk_size, \n",
    "                                      chunk_overlap=chunk_overlap) \n",
    "texts = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings(model=embedding_model, \n",
    "                              chunk_size=chunk_size,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":4})\n",
    "llm = OpenAI(model=llm_model, max_tokens=max_tokens, temperature=temperature)\n",
    "prompt_template = PromptTemplate(\n",
    "    template=prompt, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain_type_kwargs = {'prompt': prompt_template}\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                 chain_type=\"stuff\", \n",
    "                                 retriever=retriever,\n",
    "                                 chain_type_kwargs=chain_type_kwargs,\n",
    "                                 return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'How are you doing?',\n",
       " 'result': \"\\nI'm doing well. I'm feeling optimistic about 2023 and all the main parts of my life are stable. I'm continuing to focus on my goals of learning, health, and happiness.\",\n",
       " 'source_documents': [Document(page_content='Other than the standard things one does with a toddler, not much has changed on the family side. Just enjoying all of it. We’ve been spending a bit more time with the extended family too as COVID worries wane and hope to do more of it next year.\\n\\nFriends: I’ve been terrible at keeping in touch with my friends these past couple of years. I use the excuse of not being able to meet in-person combined with having a small child, but that’s a weak excuse. Recently, I’ve been trying to get in touch with some of my friends now that I’m more comfortable with limited in-person meetings. I hope I can do more of it next year.', metadata={'source': '../test.txt', 'url': 'https://xyz'}),\n",
       "  Document(page_content='Health & Fitness: On the health side, through the first half of the year, I continued to lose a bit of weight and in the last half of the year plateaued. To be honest, I’ve relaxed some of my weight loss efforts because I’m already at an acceptable weight (but who wouldn’t want to lose another 5 lbs?). The good thing is that I think I’ve successfully adopted a lot of habits that will keep the weight off, namely, eating a lot less per meal and little, if any, binge eating. We’ll see if it sticks when I (hopefully) start going out to eat at restaurants next year.', metadata={'source': '../test.txt', 'url': 'https://xyz'}),\n",
       "  Document(page_content='A good (math) metaphor I was thinking about: imagine your happiness can be modelled as a rectangle on a two dimensional plane. The area of the rectangle is your happiness from all your non-child activities e.g., friends, going out, etc. Once you have a child, this area shrinks. You no longer have much time for any of those things. No drinks with friends, no going out to the movies, drastically reduced TV time etc. BUT… what happens when you have a child is that a whole new dimension of happiness opens up with it being measured by the time spent with your child. Your happiness is no longer measured by area but by volume. So in some sense (projecting onto the two dimensional plane), your life is worse off. But when measuring using volume, your life is infinitely more rich. Not a perfect analogy but it gives you a sense of the phenomenon.', metadata={'source': '../test.txt', 'url': 'https://xyz'}),\n",
       "  Document(page_content='The Next Year\\n\\nDespite all the craziness going on in the world, I’m actually feeling optimistic about 2023. I can see a path towards more “normal” interactions where I can sit down with friends and extended family to eat a meal, have my daughter play with other kids, and do most of the things that I was doing pre-pandemic. Beyond this, all of the main parts of my life are pretty stable (after a couple year of upheaval), which will allow me to better optimize for some of my goals (e.g., learning, healthy, happiness etc.). Of course I’m sure 2023 will throw some curve balls my way, but it’s a nice feeling to be looking to the new year with a renewed sense of optimism. It’s been a tough couple of years for everyone and I know not everyone has come out as well as I have, but I truly hope that 2023 will be brighter and more joyful for both you and me.', metadata={'source': '../test.txt', 'url': 'https://xyz'})]}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How are you doing?\"\n",
    "qa({'query': query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
